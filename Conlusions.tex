\chapter{Conclusions} 
This thesis has investigated the question of whether combining meta-learning and synthetic data for real-world few-shot learning problems is a viable option to using real data, and how such data should be generated in order to maximize performance. This question has been examined by looking at the task of few-shot military vehicle classification. Synthetic data were first generated using a high-end military simulator. A neural network was then trained using model-agnostic meta-learning on several synthetic datasets with different randomization settings. The model was then evaluated on how well it could learn previously unseen few-shot tasks consisting of real-world images.

The main conclusion of this thesis is that meta-learning with synthetic training is a viable approach to training deep learning models for few-shot learning tasks. The best performing model trained with synthetic data was able to achieve 69.03\% accuracy on 5-way 5-shot classification tasks, compared to 72.88\% for an identical model trained on real-world data. The gap is more significant for 5-way 1-shot classification with 46.41\% against 62.94\%. The fast rate at which the gap in accuracy between real-world and synthetic narrows when more real-world training data is used also suggests that adding additional training data might narrow the gap between real-world and simulated data even further.

The results also suggest that small changes to the data generation process can have a significant effect on performance. Randomizing simulation lighting during training alone can, for example, increase the accuracy by more than eight percentage points. These results offer hope that further adjustments to the generation process might be able to shorten the performance difference between synthetic and real-world data even further.

\section{Future Research}
This section will outline some of the possible improvements to the thesis' approach and will also outline what avenues for future research that exist.

The poor results on the 5-way 1-shot tasks suggest that the synthetically trained models were unable to learn a sufficiently domain-agnostic feature representation to handle the domain shift. Instead, more real-world data was needed to fine-tune the models to compensate for the shift in domain. The goal should be to have the model learn a domain agnostic feature representation directly from the synthetic data, allowing it to be used directly on real-world data. In order find a domain randomization method in VBS3 which can produce such features for vehicle classification, further research into different domain randomization methods is needed.

As outlined in Section \ref{why-synthetic}, one of the main advantages of using synthetic data is that it allows for a greater range of possible tasks to be generated, compared to unlabeled approaches. As the results of this thesis show that the synthetic approach can achieve promising accuracy on few-shot tasks, the obvious next step is to apply the synthetic approach in more complex application domains. One of the more obvious choices for an application would be object-detection, object tracking, or meta-training for reinforcement-learning tasks since that kind of data can be generated easily with existing code.

Another possible avenue of improvement would be the neural network architecture. The network architecture used in this thesis is a very simplistic one, which can seem wasteful, especially since the main advantage of \gls{MAML} is model independence.  There are many reasons for being conservative about the choice of network architecture. Using networks that have been proven to work in the past is significantly more manageable, and complex networks are often difficult to train and often consume more memory, especially when using \gls{MAML}. However, being able to use more complex architecture is a requirement if more complex tasks, like object detection, are to be used with \gls{MAML}. In order for this to be viable, there are many aspects of meta-learning that needs to be investigated. One is how regularisation can be used with \gls{MAML}. Another is what kind of networks are best suited. Memory saving architectures like SqueezeNet~\cite{squeezenet} and TinySDD~\cite{tinyssd} might be a promising way forward.